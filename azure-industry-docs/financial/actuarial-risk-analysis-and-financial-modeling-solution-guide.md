---
title: 보험 통계 위험 분석을 Azure로 이동하기 위한 가이드
author: scseely
ms.author: scseely
ms.date: 11/20/2019
ms.topic: article
ms.service: industry
description: 보험 통계 개발자가 기존 솔루션과 지원 인프라를 Azure로 이동할 수 있는 방법입니다.
ms.openlocfilehash: 456c054cf3a6165f160005ba8ea2c155637faa07
ms.sourcegitcommit: f030566b177715794d2ad857b150317e72d04d64
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/20/2019
ms.locfileid: "74234531"
---
# <a name="actuarial-risk-analysis-and-financial-modeling-solution-guide"></a><span data-ttu-id="5e605-103">보험 통계 위험 분석 및 금융 모델링 솔루션 가이드</span><span class="sxs-lookup"><span data-stu-id="5e605-103">Actuarial risk analysis and financial modeling solution guide</span></span>

<span data-ttu-id="5e605-104">지난 몇 년 동안 보험 회사 및 보험 유사 상품을 제공하는 기업들은 여러 새로운 규정을 적용 받게 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-104">Over the last several years, insurers and companies that provide insurance-like products have seen several new regulations come into place.</span></span> <span data-ttu-id="5e605-105">이러한 새 규정에서는 보험 회사에 더 광범위한 재무 모델링을 요구합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-105">These new regulations have required more extensive financial modeling for insurers.</span></span> <span data-ttu-id="5e605-106">유럽 연합은 보험 회사가 연말에 지급 능력이 있음을 검증하기 위해 적합한 분석을 수행했음을 입증하도록 요구하는 [Solvency II](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138)를 시행했습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-106">The European Union enacted [Solvency II](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) which requires insurers to demonstrate that they have done proper analysis to validate that the insurer will be solvent at the end of the year.</span></span> <span data-ttu-id="5e605-107">변액연금을 제공하는 보험 회사는 광범위 자산 및 부패 현금 흐름 분석을 포함하는 [Actuarial Guideline XLIII](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138)를 따라야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-107">Insurers who provide variable annuities have to follow [Actuarial Guideline XLIII](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) with extensive analysis of asset and liability cash flows.</span></span> <span data-ttu-id="5e605-108">유사 보험 상품을 취급하는 회사를 포함한 모든 형태의 보험 회사는 2021년까지 IFRS 17([International Financial Reporting Standard 17](https://www.ifrs.org/supporting-implementation/supporting-materials-by-ifrs-standard/ifrs-17/))을 이행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-108">All types of insurers, including those who distribute insurance like products, will have to implement [International Financial Reporting Standard 17](https://www.ifrs.org/supporting-implementation/supporting-materials-by-ifrs-standard/ifrs-17/) (IFRS 17) by 2021.</span></span> <span data-ttu-id="5e605-109">보험 회사가 영업하는 사법 관할지에 따라 다른 규정도 존재합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-109">Other regulations exist depending on the jurisdictions the insurers operate in.</span></span> <span data-ttu-id="5e605-110">이러한 표준 및 규정에 따라 보험 계리인은 자산 및 부채를 모델링할 때 계산 집약적 기술을 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-110">These standards and regulations require actuaries to use compute-intensive techniques when modeling assets and liabilities.</span></span> <span data-ttu-id="5e605-111">대부분의 분석에서는 자산 및 부채 같은 순차적 입력 항목에 대해 확률적으로 생성된 시나리오 데이터를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-111">Much of the analysis will make use of stochastically generated scenario data over seriatim inputs of things like assets and liabilities.</span></span> <span data-ttu-id="5e605-112">규정 요구 사항 이외에도 보험 계리인은 규정 보고서를 생성하는 모델에 대한 입력 테이블을 생성하기 위해 상당한 분량의 재무 모델링과 연산을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-112">Beyond regulatory needs, actuaries do a fair amount of financial modeling and computation to generate the input tables for the models that generate the regulatory reports.</span></span> <span data-ttu-id="5e605-113">내부 그리드로는 계산 요구를 만족하지 못하기 때문에 보험 계리인은 꾸준히 클라우드로 이동하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-113">Internal grids do not satisfy the computational needs, so actuaries are steadily moving to the cloud.</span></span>

<span data-ttu-id="5e605-114">보험 계리인은 결과를 검토, 평가 및 검증할 시간을 더 많이 확보하기 위해 클라우드로 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-114">Actuaries move to the cloud to get more time to review, evaluate, and validate results.</span></span> <span data-ttu-id="5e605-115">규제 기관에서는 보험 회사를 감사할 때 보험 계리인은 결과를 설명할 수 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-115">When regulators audit insurers, the actuaries need to be able to explain their results.</span></span> <span data-ttu-id="5e605-116">클라우드로 이동하면 병렬 처리 능력을 통해 24~120시간에 20000시간 분량의 분석을 수행할 수 있는 연산 자원을 사용할 수 있게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-116">The move to the cloud gives access to the computing resources to run 20000 hours of analysis in 24-120 hours of clock time through the power of parallelization.</span></span> <span data-ttu-id="5e605-117">이런 규모에의 요구를 지원하기 위해 보험 계리 소프트웨어를 제작하는 많은 기업에서는 Azure에서의 계산 실행을 허용하는 솔루션을 제공하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-117">To assist with this need for scale, many of the companies that create actuarial software provide solutions that allow calculations to run in Azure.</span></span> <span data-ttu-id="5e605-118">이중 일부 솔루션은 [HPC Pack](https://docs.microsoft.com/powershell/high-performance-computing/overview?view=hpc16-ps&WT.mc_id=riskmodel-docs-scseely) 같은 Azure 및 온-프레미스에서 실행되는 기술을 바탕으로 구축됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-118">Some of these solutions are built on technologies that run on premises and Azure like [HPC Pack](https://docs.microsoft.com/powershell/high-performance-computing/overview?view=hpc16-ps&WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-119">다른 솔루션은 Azure 네이티브로, [Azure Batch](https://docs.microsoft.com/azure/batch?WT.mc_id=riskmodel-docs-scseely), [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets?WT.mc_id=riskmodel-docs-scseely) 또는 사용자 지정 크기 조정 솔루션을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-119">Others are Azure native and use [Azure Batch](https://docs.microsoft.com/azure/batch?WT.mc_id=riskmodel-docs-scseely), [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets?WT.mc_id=riskmodel-docs-scseely), or a custom scaling solution.</span></span>

<span data-ttu-id="5e605-120">이 문서에서는 보험 계리 관련 개발자들이 어떻게 Azure를 모델링 패키지와 함께 사용하여 위험을 분석할 수 있는지 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-120">In this article, we will look at how actuarial developers can use Azure, coupled with modeling packages, to analyze risk.</span></span> <span data-ttu-id="5e605-121">이 문서에서는 모델링 패키지가 Azure 규모에서실행하기 위해 사용하는 일부 Azure 기술에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-121">The article explains some of the Azure technologies the modeling packages use to run at scale on Azure.</span></span> <span data-ttu-id="5e605-122">같은 기술을 사용하여 데이터를 더 심층적으로 분석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-122">You can use the same technology to do further analysis of your data.</span></span> <span data-ttu-id="5e605-123">다음 항목을 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-123">We look at the following items:</span></span>

- <span data-ttu-id="5e605-124">Azure에서 짧은 시간에 더 큰 모델 실행</span><span class="sxs-lookup"><span data-stu-id="5e605-124">Running larger models in less time, in Azure.</span></span>
- <span data-ttu-id="5e605-125">결과에 대한 보고</span><span class="sxs-lookup"><span data-stu-id="5e605-125">Reporting on the results.</span></span>
- <span data-ttu-id="5e605-126">데이터 보존 관리</span><span class="sxs-lookup"><span data-stu-id="5e605-126">Managing data retention.</span></span>

<span data-ttu-id="5e605-127">생명, 재산, 상해, 건강 또는 기타 보험 등, 어떤 보험을 서비스하던 보험 회사로서의 지급 능력을 유지할 수 있게 투자와 보험료를 조정하려면 자산과 부채에 관한 재무 및 위험 모델을 만들어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-127">Whether you are servicing life, property and casualty, health, or other insurance, you need to create financial and risk models of your assets and liabilities to adjust your investments and premiums so that you stay solvent as an insurer.</span></span> <span data-ttu-id="5e605-128">IFRS 17 보고에 따라 CSM(약정 서비스 이익) 산출 등, 보험 계리인이 만드는 모델의 변화도 필요한데 이로 인해 보험 회사가 시간에 따라 수익을 관리하는 방식도 변화하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-128">IFRS 17 reporting adds changes to the models the actuaries create, like calculating the contractual service margin (CSM), which change how insurers manage their profit through time.</span></span>

## <a name="running-more-in-less-time-in-azure"></a><span data-ttu-id="5e605-129">Azure에서 더 적은 시간에 더 많은 항목 실행</span><span class="sxs-lookup"><span data-stu-id="5e605-129">Running more in less time, in Azure</span></span>

<span data-ttu-id="5e605-130">클라우드가 재무 및 위험 모델을 더 빠르고 쉽게 실행한다는 사실을 믿어 의심치 않습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-130">You believe in the promise of the cloud: it can run your financial and risk models faster and easier.</span></span> <span data-ttu-id="5e605-131">많은 보험 회사들은 외면적 계산의 이면에서 여러 문제를 확인할 수 있었습니다. 이러한 계산을 시작부터 끝까지 모두 실행하려면 몇 년, 심지어 몇십 년의 시간이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-131">For many insurers, a back of the envelope calculation shows the problem: they need years, or even decades, of sequential time to run these calculations from start to finish.</span></span> <span data-ttu-id="5e605-132">이러한 실행 시간 문제를 해결하기 위한 기술이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-132">You need technology to solve the runtime problem.</span></span> <span data-ttu-id="5e605-133">전략은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-133">Your strategies are:</span></span>

- <span data-ttu-id="5e605-134">데이터 준비: 일부 데이터는 느리게 변경됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-134">Data preparation: Some data changes slowly.</span></span> <span data-ttu-id="5e605-135">정책 또는 서비스 계약이 적용되면 청구가 예측 가능한 단계로 진행됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-135">Once a policy or service contract is in force, claims move at a predictable pace.</span></span> <span data-ttu-id="5e605-136">도착하면 모델 실행에 필요한 데이터를 준비할 수 있으므로 데이터 정리 및 준비를 위해 상당한시간을 계획할 필요가 없어집니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-136">You can prepare the data needed for model runs as it arrives, eliminating a need to plan much time for data cleansing and preparation.</span></span> <span data-ttu-id="5e605-137">가중치가 적용된 표현을 통해 순차적 데이터에 대한 대용물을 만드는 데 클러스터링을 사용할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-137">You may also use clustering to create stand-ins for seriatim data through weighted representations.</span></span> <span data-ttu-id="5e605-138">레코드 수가 적을수록 보통 계산 시간이 줄어듭니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-138">Fewer records usually results in reduced computation time.</span></span>
- <span data-ttu-id="5e605-139">병렬 처리: 둘 이상의 항목에 대해 같은 분석을 수행해야 할 경우 동시에 분석을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-139">Parallelization: If you need to do the same analysis to two or more items, you may be able to perform the analysis simultaneously.</span></span>

<span data-ttu-id="5e605-140">이 항목을 개별적으로 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-140">Let's look at these items individually.</span></span>

### <a name="data-preparation"></a><span data-ttu-id="5e605-141">데이터 준비</span><span class="sxs-lookup"><span data-stu-id="5e605-141">Data Preparation</span></span>

<span data-ttu-id="5e605-142">여러 다른 원본에서의 데이터 흐름.</span><span class="sxs-lookup"><span data-stu-id="5e605-142">Data flows in from several different sources.</span></span> <span data-ttu-id="5e605-143">비즈니스 장부에 반 구조화된 약관 데이터가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-143">You have semi-structured policy data in your books of business.</span></span> <span data-ttu-id="5e605-144">다양한 신청서에 등장하는 피보험자, 회사, 항목에 대한 정보입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-144">Information about the insured people, companies, and the items which appear in various application forms.</span></span> <span data-ttu-id="5e605-145">ESG(경제 시나리오 생성기)는 모델이 사용할 수 있는 양식으로의 변환이 필요할 수 있는 다양한 형식의 데이터를 생산합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-145">Economic Scenario Generators (ESGs) produce data in a variety of formats which may need translation to a form your model can use.</span></span> <span data-ttu-id="5e605-146">자산 가치에 관한 현재 데이터도 정규화가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-146">Current data on values of assets also needs normalization.</span></span> <span data-ttu-id="5e605-147">주식 시장 데이터, 임대 현금 흐름 데이터, 모기지 납부 정보, 기타 자산 데이터는 모두 원본에서 모델로 이동할 때 어떤 준비가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-147">The stock market data, cash flow data on rentals, payment information on mortgages, and other asset data all need some preparation when moving from the source to the model.</span></span> <span data-ttu-id="5e605-148">마지막으로, 최신 환경 데이터를 기준으로 가정을 업데이트할 필요가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-148">Finally, you should update any assumptions based on recent experience data.</span></span> <span data-ttu-id="5e605-149">모델 실행 속도를 높이기 위해 미리 데이터를 준비합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-149">To speed up a model run, you prepare the data ahead of time.</span></span> <span data-ttu-id="5e605-150">실행 시간이 되면 마지막 예약 업데이트 이후 변경을 추가하기 위해 필요한 업데이트를 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-150">When run time happens, you do any necessary updates to add in changes since the last scheduled update.j</span></span>

<span data-ttu-id="5e605-151">자, 어떻게 데이터를 준비할까요?</span><span class="sxs-lookup"><span data-stu-id="5e605-151">So, how do you prepare the data?</span></span> <span data-ttu-id="5e605-152">먼저 공통된 부분을 살펴본 다음, 데이터가 표시되는 다양한 방식을 작업하는 방법에 대해 알아보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-152">Let's first look at the common bits and then look at how to work with the different ways data will appear.</span></span> <span data-ttu-id="5e605-153">먼저 지난 동기화 이후 모든 변경 내용을 확보하기 위한 메커니즘이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-153">First, you want a mechanism to get all the changes since the last synchronization.</span></span> <span data-ttu-id="5e605-154">이 메커니즘은 정렬 가능한 값을 포함해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-154">That mechanism should include a value which is sortable.</span></span> <span data-ttu-id="5e605-155">최근 변경 내용에 대해 이 값은 이전 변경 내용보다 커야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-155">For recent changes, that value should be greater than any previous change.</span></span> <span data-ttu-id="5e605-156">가장 일반적인 두 메커니즘은 계속 증가하는 ID 필드 또는 타임스탬프입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-156">The two most common two mechanisms are an ever-increasing ID field or a timestamp.</span></span> <span data-ttu-id="5e605-157">레코드에 증가하는 ID 키가 있으나 나머지 레코드는 업데이트 가능한 필드를 포함할 경우 &quot;마지막으로 수정된&quot; 타임스탬프 같은 항목을 사용하여 변경 내용을 찾아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-157">If a record has an increasing ID key but the rest of the record contains fields which can be updated, you need to use something like a &quot;last-modified&quot; timestamp to find changes.</span></span> <span data-ttu-id="5e605-158">레코드를 처리한 후에는 지난 업데이트 항목의 정렬 가능한 값을 기록합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-158">Once the records have been processed, record the sortable value of the last item updated.</span></span> <span data-ttu-id="5e605-159">_lastModified_라고 하는 필드의 타임스탬프일 수 있는 이 값은 데이터 저장소에 대한 후속 쿼리에 사용되는 워터마크가 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-159">This value, probably a timestamp on a field called _lastModified_, becomes your watermark, used for subsequent queries on the data store.</span></span> <span data-ttu-id="5e605-160">데이터 변경 내용은 여러 가지 방법으로 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-160">Data changes can be processed in many ways.</span></span> <span data-ttu-id="5e605-161">최소 리소스를 사용하는 일반적인 두 가지 메커니즘은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-161">Here are two common mechanisms which use minimal resources:</span></span>

1. <span data-ttu-id="5e605-162">처리해야 할 변경 내용이 수백 또는 수천 개인 경우 다음을 수행합니다. 데이터를 Blob 스토리지에 업로드합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-162">If you have hundreds or thousands of changes to process: Upload the data to blob storage.</span></span> <span data-ttu-id="5e605-163">[Azure Data Factory](https://docs.microsoft.com/azure/data-factory?WT.mc_id=riskmodel-docs-scseely)에서 이벤트 트리거를 사용하여 변경 세트를 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-163">Use an event trigger in [Azure Data Factory](https://docs.microsoft.com/azure/data-factory?WT.mc_id=riskmodel-docs-scseely) to process the changeset.</span></span>
2. <span data-ttu-id="5e605-164">처리해야 할 변경 내용 세트가 소규모이거나 변경 발생 즉시 데이터를 업데이트하려는 경우 각 변경 내용을 [Service Bus](https://docs.microsoft.com/azure/service-bus-messaging?WT.mc_id=riskmodel-docs-scseely)나 [스토리지 큐](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction?WT.mc_id=riskmodel-docs-scseely)에서 호스트하는 큐 메시지에 넣습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-164">If you have small sets of changes to process or want to update your data as soon as a change happens, put each change into a queue message hosted by [Service Bus](https://docs.microsoft.com/azure/service-bus-messaging?WT.mc_id=riskmodel-docs-scseely) or [Storage Queues](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-165">[이 문서에서는](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted?WT.mc_id=riskmodel-docs-scseely) 두 큐 기술 간의 절충 문제를 잘 설명하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-165">[This article](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted?WT.mc_id=riskmodel-docs-scseely) has a great explanation about the tradeoffs between the two queueing technologies.</span></span> <span data-ttu-id="5e605-166">메시지가 큐에 들어가면 Azure Functions 또는 Azure Data Factory에서 메시지를 처리하기 위해 트리거를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-166">Once a message is in a queue, you can use a trigger in Azure Functions or Azure Data Factory to process the message.</span></span>

<span data-ttu-id="5e605-167">다음 그림은 일반적인 시나리오를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-167">The following figure illustrates a typical scenario.</span></span> <span data-ttu-id="5e605-168">먼저 예약된 작업이 일부 데이터 세트를 수집하고 파일을 스토리지에 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-168">First, a scheduled job collects some set of data and places the file into storage.</span></span> <span data-ttu-id="5e605-169">예약된 작업은 온-프레미스에서 실행되는 CRON 작업이거나, 타이머에서 실행되는 [스케줄러 작업](https://docs.microsoft.com/azure/scheduler?WT.mc_id=riskmodel-docs-scseely), [논리 앱](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=riskmodel-docs-scseely) 또는 기타 항목이 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-169">The scheduled job can be a CRON job running on premises, a [Scheduler task](https://docs.microsoft.com/azure/scheduler?WT.mc_id=riskmodel-docs-scseely), [Logic App](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=riskmodel-docs-scseely), or anything that runs on a timer.</span></span> <span data-ttu-id="5e605-170">파일이 업로드되면 [Azure Function](https://docs.microsoft.com/azure/azure-functions?WT.mc_id=riskmodel-docs-scseely) 또는 **Data Factory** 인스턴스를 트리거하여 데이터를 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-170">Once the file is uploaded, an [Azure Function](https://docs.microsoft.com/azure/azure-functions?WT.mc_id=riskmodel-docs-scseely) or **Data Factory** instance can be triggered to process the data.</span></span> <span data-ttu-id="5e605-171">파일이 단시간에 처리될 경우 **함수**를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-171">If the file can be processed in a short period of time, use a **Function**.</span></span> <span data-ttu-id="5e605-172">처리가 복잡하여 AI 또는 기타 복합 스크립팅이 필요한 경우 [HDInsight](https://docs.microsoft.com/azure/hdinsight?WT.mc_id=riskmodel-docs-scseely), [Azure Databricks](https://docs.microsoft.com/azure/azure-databricks?WT.mc_id=riskmodel-docs-scseely) 또는 다른 사용자 지정 항목이 더 효율적일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-172">If the processing is complex, requires AI or other complex scripting, you may find that [HDInsight](https://docs.microsoft.com/azure/hdinsight?WT.mc_id=riskmodel-docs-scseely), [Azure Databricks](https://docs.microsoft.com/azure/azure-databricks?WT.mc_id=riskmodel-docs-scseely), or something custom works better.</span></span> <span data-ttu-id="5e605-173">마쳤으면 파일이 데이터베이스의 새 파일이나 레코드 형태의 사용 가능한 양식으로 정리됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-173">When done, the file winds up in a usable form as a new file or as records in a database.</span></span>

 ![](./assets/insurance-risk-assets/process-files.png)

<span data-ttu-id="5e605-174">데이터가 Azure에 있으면 모델링 애플리케이션을 통해 사용할 수 있게 만들어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-174">Once the data is in Azure, you need to make it usable by the modeling application.</span></span> <span data-ttu-id="5e605-175">사용자 지정 변환을 수행하고, **HDInsight** 또는 Azure **Databricks**을 통해 항목을 실행하여 더 큰 항목을 주입하거나 데이터를 올바른 데이터 세트에 복사하는 코드를 작성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-175">You can write code to do custom transformations, run the items through **HDInsight** or Azure **Databricks** to ingest larger items, or copy the data into the right data sets.</span></span> <span data-ttu-id="5e605-176">빅 데이터 도구를 사용하는 것도 비정형 데이터를 구조화된 데이터로 변환하거나 수신된 데이터에서 AI 및 ML을 실행하는 등의 작업에 유용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-176">The use of big data tools can also help you do things like transform unstructured data into structured data as well as run any AI and ML over the received data.</span></span> <span data-ttu-id="5e605-177">가상 머신을 호스트하고, 데이터를 직접 온-프레미스에서 데이터 원본에 업로드하고, Azure Functions를 직접 호출하는 등의 작업도 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-177">You can also host virtual machines, upload data straight to data sources from on-premises, call Azure Functions directly, and so on.</span></span>

<span data-ttu-id="5e605-178">나중에 이 데이터를 모델에서 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-178">Later, the data needs to be consumed by your models.</span></span> <span data-ttu-id="5e605-179">이를 위한 방법은 계산에서 데이터에 액세스하는 방법에 따라 크게 좌우됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-179">The way you do this depends largely on how the calculations need to access data.</span></span> <span data-ttu-id="5e605-180">일부 모델링 시스템에서는 모든 데이터 파일이 계산을 실행하는 노드에 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-180">Some modeling systems require all data files to live on the node that runs the calculation.</span></span> <span data-ttu-id="5e605-181">다른 경우 [Azure SQL Database](https://docs.microsoft.com/azure/sql-database/?WT.mc_id=riskmodel-docs-scseely), [MySQL](https://docs.microsoft.com/azure/mysql/?WT.mc_id=riskmodel-docs-scseely), 또는 [PostgreSQL](https://docs.microsoft.com/azure/postgresql/?WT.mc_id=riskmodel-docs-scseely) 같은 데이터베이스를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-181">Others can make use of databases like [Azure SQL Database](https://docs.microsoft.com/azure/sql-database/?WT.mc_id=riskmodel-docs-scseely), [MySQL](https://docs.microsoft.com/azure/mysql/?WT.mc_id=riskmodel-docs-scseely), or [PostgreSQL](https://docs.microsoft.com/azure/postgresql/?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-182">이러한 항목의 저비용 버전을 사용한 다음, 모델링 실행 중에 성능을 강화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-182">You can use a low-cost version of any of these items, and then scale up the performance during a modeling run.</span></span> <span data-ttu-id="5e605-183">이렇게 하면 일상 업무에 필요한 가격을 적용하면서도 수천 개 코어가 데이터를 요청할 때만 추가 속도를 확보할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-183">This gives you the price you need for every day work, plus the extra speed just when thousands of cores are requesting data.</span></span> <span data-ttu-id="5e605-184">일반적으로 이 데이터는 모델링 실행 중에 읽기 전용 상태입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-184">Normally, this data will be read-only during a modeling run.</span></span> <span data-ttu-id="5e605-185">여러 지역에서 계산이 발생할 경우 [Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/distribute-data-globally?WT.mc_id=riskmodel-docs-scseely) 또는 [Azure SQL 지역 복제](https://docs.microsoft.com/azure/sql-database/sql-database-geo-replication-overview?WT.mc_id=riskmodel-docs-scseely)를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-185">If your calculations occur across multiple regions, consider using [Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/distribute-data-globally?WT.mc_id=riskmodel-docs-scseely) or [Azure SQL geo-replication](https://docs.microsoft.com/azure/sql-database/sql-database-geo-replication-overview?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-186">모두 낮은 대기 시간에서 지역 간에 데이터를 자동으로 복제하는 메커니즘을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-186">Both provide mechanisms to automatically replicate data across regions with low latency.</span></span> <span data-ttu-id="5e605-187">개발자가 알고 있는 도구, 데이터를 모델링한 방법, 모델링 실행에 사용된 지역 수에 따라 메커니즘을 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-187">Your choice depends on the tools your developers know, how you have modeled your data, and the number of regions used for your modeling run.</span></span>

<span data-ttu-id="5e605-188">데이터를 저장할 위치에 관해서는 세심히 생각할 필요가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-188">Do spend some time thinking about where to store your data.</span></span> <span data-ttu-id="5e605-189">동일한 데이터에 대한 동시 요청 수가 얼마나 될지를 이해해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-189">Understand how many simultaneous requests for the same data will exist.</span></span> <span data-ttu-id="5e605-190">정보 배포는 방법을 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-190">Think about how you will distribute the information:</span></span>

- <span data-ttu-id="5e605-191">각 계산 노드에 자체 사본이 있나요?</span><span class="sxs-lookup"><span data-stu-id="5e605-191">Does each computational node get its own copy?</span></span>
- <span data-ttu-id="5e605-192">이 사본이 고대역폭 위치를 통해 공유되나요?</span><span class="sxs-lookup"><span data-stu-id="5e605-192">Is the copy shared through some high bandwidth location?</span></span>

<span data-ttu-id="5e605-193">Azure SQL을 사용하여 데이터를 중앙 집중식으로 유지한다면 데이터베이스를 대부분의 시간에는 더 낮은 가격의 계층에 유지할 가능성이 높습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-193">If you keep data centralized using Azure SQL, you will likely keep the database at a lower priced tier most of the time.</span></span> <span data-ttu-id="5e605-194">데이터가 모델링 실행 중에만 사용되며 자주 업데이트되지 않는다면 Azure 고객은 데이터를 백업하고 실행 사이에는 데이터베이스 인스턴스를 끄는 방식으로 진행하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-194">If the data is only used during a modeling run and is not updated very often, Azure customers will go so far as to backup the data and turn off their database instances in between runs.</span></span> <span data-ttu-id="5e605-195">이렇게 하면 큰 금액을 절약할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-195">The potential savings are large.</span></span> <span data-ttu-id="5e605-196">고객은 [Azure SQL Elastic Pool](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-pool?WT.mc_id=riskmodel-docs-scseely)도 이용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-196">Customers can also make use of [Azure SQL Elastic Pools](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-pool?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-197">이들은 데이터베이스 비용을 억제하기 위해 설계되었습니다. 특히 서로 다른 시간대에 어떤 데이터베이스에 로드가 클지 모르는 상태에서 그렇습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-197">These are designed to control database costs, especially when you do not know which databases will be under a lot of load at different times.</span></span> <span data-ttu-id="5e605-198">탄력적 풀을 사용하면 데이터베이스 컬렉션이 필요한 만큼의 능력을 사용한 다음, 시스템 어딘가에서 수요가 바뀌면 다시 규모를 되돌릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-198">The elastic pools allow a collection of databases to use as much power as they need, then scale back once demand shifts elsewhere in the system.</span></span>

<span data-ttu-id="5e605-199">나중에 프로세스에서 계산이 같은 데이터를 사용할 수 있게 모델링 실행 중에 데이터 동기화를 사용하지 않게 설정해야 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-199">You may need to disable data synchronization during a modeling run so that calculations later in the process are using the same data.</span></span> <span data-ttu-id="5e605-200">큐를 사용할 경우 메시지 프로세서를 사용하지 않게 하면서 큐가 데이터를 수신할 수 있게 허용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-200">If you are using queuing, disable the message processors but allow the queues to receive data.</span></span>

<span data-ttu-id="5e605-201">또한 경제 시나리오를 생성하고, 보험 계리 가정을 업데이트하며, 일반적으로 다른 고정 데이터를 업데이트하기 위해 실행 전 시간을 사용할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-201">You can also use the time before the run to generate economic scenarios, update actuarial assumptions, and generally update other static data.</span></span> <span data-ttu-id="5e605-202">ESG(경제 시나리오 생성)를 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-202">Let's look at economic scenario generation (ESG).</span></span> <span data-ttu-id="5e605-203">[보험 계리인 협회](https://www.soa.org/)는 미국 재무부 결과를 모델링하는 [AIRG(Academy Interest Rate Generator)](https://www.soa.org/tables-calcs-tools/research-scenario/)를</span><span class="sxs-lookup"><span data-stu-id="5e605-203">The [Society of Actuaries](https://www.soa.org/) provides the [Academy Interest Rate Generator](https://www.soa.org/tables-calcs-tools/research-scenario/) (AIRG), an ESG which models U. S.</span></span> <span data-ttu-id="5e605-204">제공합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-204">Treasury yields.</span></span> <span data-ttu-id="5e605-205">AIRG는 VM-20(Valuation Manual 20) 계산 같은 항목에서 사용하기 위해 미리 지정됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-205">AIRG is prescribed for use in items like Valuation Manual 20 (VM-20) calculations.</span></span> <span data-ttu-id="5e605-206">다른 ESG는 주식 시장, 모기지, 상품 가격 등을 모델링할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-206">Other ESGs may model the stock market, mortgages, commodity prices, and so on.</span></span>

<span data-ttu-id="5e605-207">환경에서 데이터를 미리 처리하므로 다른 부분도 일찍 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-207">Because your environment ispreprocessing the data, you can also run other pieces early.</span></span> <span data-ttu-id="5e605-208">예를 들어, 더 큰 모집단을 나타내기 위해 레코드를 사용하는 yv1ou 모델링 항목이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-208">For example, you may have things which yv1ou model that use records to represent larger populations.</span></span> <span data-ttu-id="5e605-209">보통은 레코드 클러스터링을 통해 이를 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-209">One usually does this by clustering records.</span></span> <span data-ttu-id="5e605-210">데이터 세트가 하루 한 번처럼 산발적으로 업데이트될 경우 주입 프로세스의 일환으로 모델에서 사용되는 레코드 세트를 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-210">If the dataset is updated sporadically, such as once a day, one can reduce the record set to what will be used in the model as part of the ingestion process.</span></span>

<span data-ttu-id="5e605-211">실제 예제를 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-211">Let's look at a practical example.</span></span> <span data-ttu-id="5e605-212">IFRS-17에서는 두 계약 시작일 간의 최대 차이가 1년 미만이 되도록 계약을 하나로 그룹화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-212">With IFRS-17, you need to group your contracts together such that the maximum distance between the start dates for any two contracts is under one year.</span></span> <span data-ttu-id="5e605-213">이를 간편하게 하기 위해 계약 연도를 그룹화 메커니즘으로 사용한다고 가정해 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-213">Let's assume that you do this the easy way and use the contract year as the grouping mechanism.</span></span> <span data-ttu-id="5e605-214">이러한 구분은 데이터를 Azure에 로드하는 동안 파일을 통해 레코드를 읽고 적합한 연도 그룹으로 이동하여 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-214">This segmentation can be done while data is loaded into Azure by reading through the file and moving the records to the appropriate year groupings.</span></span>

<span data-ttu-id="5e605-215">데이터 준비에 집중하면 모델 구성 요소 실행에 필요한 시간이 줄어듭니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-215">Focusing on data preparation reduces the time necessary to run the model components.</span></span> <span data-ttu-id="5e605-216">초기에 데이터를 가져오면 모델 실행을 위한 클록 시간을 절약할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-216">By getting the data in early, you can save clock time for running your models.</span></span>

### <a name="parallelization"></a><span data-ttu-id="5e605-217">병렬 처리</span><span class="sxs-lookup"><span data-stu-id="5e605-217">Parallelization</span></span>

<span data-ttu-id="5e605-218">적절한 단계의 병렬 처리는 클록 실행 시간을 크게 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-218">Proper parallelization of the steps can shrink clock execution time dramatically.</span></span> <span data-ttu-id="5e605-219">이러한 속도 향상은 구현하는 부분을 간소화하고 둘 이상의 작업이 동시에 실행되게 하는 방식으로 모델을 표현하는 방식을 인지함으로써 가능합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-219">This speedup happens by streamlining the pieces that you implement and knowing how to express your model in a way that allows for two or more activities to run simultaneously.</span></span> <span data-ttu-id="5e605-220">여기서의 핵심은 작업 요청 크기와 개별 노드 생산성 간의 균형을 찾는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-220">The trick is to find balance between the size of the work request and the productivity of an individual node.</span></span> <span data-ttu-id="5e605-221">작업이 평가에서보다 설정 및 정리에 더 많은 시간이 소요된다면 너무 적게 지정한 것입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-221">If the task spends more time in setup and cleanup than it does in evaluation, you went too small.</span></span> <span data-ttu-id="5e605-222">작업이 너무 크면 실행 시간이 향상되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-222">If the task is too large, execution time does not improve.</span></span> <span data-ttu-id="5e605-223">여러 노드에 분산되는 정도의 작업이 필요하고 실행 소요 시간에서 긍정적인 변화를 주고자 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-223">You want the activity to be small enough to spread over multiple nodes and make a positive difference in elapsed execution time.</span></span>

<span data-ttu-id="5e605-224">시스템을 최대한 활용하려면 모델 워크플로와, 계산이 확장 기능과 상호 작용하는 방식을 이해해야 합니다. 소프트웨어에는 작업, 임무 또는 유사한 항목에 대한 개념이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-224">To get the most out of your system, you need to understand the workflow for your model and how the computations interact with the ability to scale out. Your software may have a notion of jobs, tasks, or something similar.</span></span> <span data-ttu-id="5e605-225">이런 지식을 통해 작업을 분할할 수 있는 무언가를 설계합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-225">Use that knowledge to design something that can split work up.</span></span> <span data-ttu-id="5e605-226">모델에 사용자 지정 단계가 있다면 처리를 위해 입력을 더 작은 그룹으로 분할할 수 있게 설계합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-226">If you have some custom steps in your model, design those to allow for inputs to be split into smaller groups for processing.</span></span> <span data-ttu-id="5e605-227">종종 이를 분산-수집 패턴이라고 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-227">Oftentimes, this is referred to as a scatter-gather pattern.</span></span>

- <span data-ttu-id="5e605-228">분산형: 자연스러운 흐름에 따라 입력을 분할하고 별도 작업의 실행을 허용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-228">Scatter: Split the inputs along natural lines and allow separate tasks to run.</span></span>
- <span data-ttu-id="5e605-229">수집: 작업이 완료되면 해당 출력을 수집합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-229">Gather: As the tasks complete, collect their outputs.</span></span>

<span data-ttu-id="5e605-230">분할 시 진행에 앞서 프로세스를 동기화해야 하는 위치도 인지합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-230">When splitting things, also know where the process needs to synchronize before moving forward.</span></span> <span data-ttu-id="5e605-231">분할을 수행하는 공통 위치가 몇 가지 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-231">There are a few common places people split things up.</span></span> <span data-ttu-id="5e605-232">중첩된 통계 실행의 경우 백 가지 시나리오의 내부 루프를 실행하는 굴곡 지점 세트와 천 개의 외부 루프가 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-232">For nested stochastic runs, you may have a thousand outer loops with a set of inflection points that run inner loops of one hundred scenarios.</span></span> <span data-ttu-id="5e605-233">각 외부 루프는 동시에 실행될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-233">Each outer loop can run simultaneously.</span></span> <span data-ttu-id="5e605-234">굴곡 지점에서 멈춘 다음, 내부 루프를 동시에 실행하고 정보를 다시 가져와 외부 루프에 대한 데이터를 조정하고, 다시 이어갑니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-234">You halt at an inflection point, then run the inner loops simultaneously, bring the information back to adjust the data for the outer loop, and go forward again.</span></span> <span data-ttu-id="5e605-235">다음 그림은 이 워크플로를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-235">The following figure demonstrates illustrates the workflow.</span></span> <span data-ttu-id="5e605-236">충분한 컴퓨팅이 있으면 100,000개 코어에서 100,000개 내부 루프를 실행할 수 있으므로 처리 시간을 다음 시간의 합계까지 단축할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-236">Given enough compute, you can run the 100,000 inner loops on 100,000 cores, bringing processing time down to the sum of the following times:</span></span>

![](./assets/insurance-risk-assets/timing.png)

<span data-ttu-id="5e605-237">배포는 수행 방법에 따라 다소 증대할 수 있습니다. 올바른 매개 변수에서는 작은 작업 구조화처럼 간단할 것이고 올바른 위치에 100K 파일을 복사하는 것처럼 복잡할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-237">Distribution will increase a bit depending on how that is done; it may be as simple as constructing a small job with the right parameters or as complex as copying 100K files to the right places.</span></span> <span data-ttu-id="5e605-238">HD Insight의 Apache Spark, Azure Databricks 또는 자체 배포를 사용하여 결과 집계를 배포할 수 있는 경우 처리 결과는 더 단축될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-238">Processing results can even be sped up if you can distribute the result aggregation using Apache Spark from HD Insight, Azure Databricks, or your own deployment.</span></span> <span data-ttu-id="5e605-239">예를 들어, 평균 계산은 지금까지 나타난 항목 수와 합계를 기억하기만 하면 되는 간단한 사안입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-239">For example, computing averages is a simple matter of remembering the number of items seen so far and the sum.</span></span> <span data-ttu-id="5e605-240">다른 계산은 수천 개 코어의 단일 머신에서 더 잘 작동할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-240">Other computations may work better on a single machine with thousands of cores.</span></span> <span data-ttu-id="5e605-241">이 경우 Azure에서 GPU 지원 머신을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-241">For those, you can make use of GPU enabled machines in Azure.</span></span>

<span data-ttu-id="5e605-242">대부분의 보험 계리 팀은 모델을 Azure로 이동하는 것부터 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-242">Most actuarial teams start this journey by moving their models to Azure.</span></span> <span data-ttu-id="5e605-243">그런 다음, 프로세스의 다양한 단계에서 시간 데이터를 수집합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-243">They then collect timing data on the various steps in the process.</span></span> <span data-ttu-id="5e605-244">다음으로 각 단계의 클록 시간을 가장 긴 소요 시간에서 가장 짧은 소요 시간으로 정렬합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-244">They then sort the clock time for each step from longest to shortest elapsed time.</span></span> <span data-ttu-id="5e605-245">어떤 항목은 수천 코어 시간을 사용하면서도 소요 시간은 20분에 지나지 않을 수 있으므로 총 실행 시간은 살피지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-245">They will not look at total execution time since something may consume thousands of core hours but only 20 minutes elapsed time.</span></span> <span data-ttu-id="5e605-246">가장 길게 실행되는 작업의 각 단계에 대해 보험 계리 개발자들은 소요 시간을 줄이면서 올바른 결과를 가져오는 방법을 모색합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-246">For each of the longest running job steps, the actuarial developers look for ways to decrease the elapsed time while getting the right results.</span></span> <span data-ttu-id="5e605-247">이 프로세스는 정기적으로 반복됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-247">This process repeats regularly.</span></span> <span data-ttu-id="5e605-248">일부 보험 계리 팀에서는 목표 실행 시간을 정할 수 있습니다. 8시간 미만으로 실행되는 것을 목표로 하는 야간 방어 분석을 가정해 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-248">Some actuarial teams will set a target run time, let's say an overnight hedging analysis has a goal of running in under 8 hours.</span></span> <span data-ttu-id="5e605-249">시간이 8.25시간을 넘어선 즉시 일부 보험 계리 팀을 전환하여 분석에서 가장 길게 실행되는 부분의 시간을 개선합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-249">As soon as the time creeps over 8.25 hours, some part of the actuarial team will switch over to improve the time of the longest piece in the analysis.</span></span> <span data-ttu-id="5e605-250">이 시간을 7.5시간으로 되돌리면 다시 개발로 전환됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-250">Once they get the time back under 7.5 hours, they switch back to development.</span></span> <span data-ttu-id="5e605-251">복귀 및 최적화를 위한 추론은 보험 계리마다 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-251">The heuristics to go back and optimize vary amongst actuaries.</span></span>

<span data-ttu-id="5e605-252">이를 모두 실행하기 위해 여러 가지 옵션이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-252">To run all this, you have several options.</span></span> <span data-ttu-id="5e605-253">대부분의 보험 계리 소프트웨어는 컴퓨팅 그리드에서 작동합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-253">Most actuarial software works with compute grids.</span></span> <span data-ttu-id="5e605-254">온-프레미스 및 Azure에서 작동하는 그리드는 [HPC Pack](https://docs.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options?WT.mc_id=riskmodel-docs-scseely), 타사 패키지 또는 사용자 지정 항목을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-254">Grids that work on-premises and on Azure use either [HPC Pack](https://docs.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options?WT.mc_id=riskmodel-docs-scseely), a third party package, or something custom.</span></span> <span data-ttu-id="5e605-255">Azure에 최적화된 그리드는 [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/?WT.mc_id=riskmodel-docs-scseely), [Batch](https://docs.microsoft.com/azure/batch/?WT.mc_id=riskmodel-docs-scseely) 또는 사용자 지정 항목을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-255">Grids optimized for Azure will use [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/?WT.mc_id=riskmodel-docs-scseely), [Batch](https://docs.microsoft.com/azure/batch/?WT.mc_id=riskmodel-docs-scseely), or something custom.</span></span> <span data-ttu-id="5e605-256">Scale Sets 또는 Batch를 사용할 경우 우선 순위가 낮은 VM([Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-low-priority?WT.mc_id=riskmodel-docs-scseely) 낮은 우선 순위 문서, [Batch](https://docs.microsoft.com/azure/batch/batch-low-pri-vms?WT.mc_id=riskmodel-docs-scseely) 낮은 우선 순위 문서)에 대한 지원을 살펴야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-256">If you choose to use either Scale Sets or Batch, make sure to look at their support for low priority VMs ([Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-low-priority?WT.mc_id=riskmodel-docs-scseely) low priority docs, [Batch](https://docs.microsoft.com/azure/batch/batch-low-pri-vms?WT.mc_id=riskmodel-docs-scseely) low priority docs).</span></span> <span data-ttu-id="5e605-257">우선 순위가 낮은 VM은 정상가의 일부 금액으로 대여할 수 있는 하드웨어에서 실행되는 VM입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-257">A low priority VM is a VM running on hardware which you can rent for a fraction of the normal price.</span></span> <span data-ttu-id="5e605-258">우선 순위가 낮은 VM은 용량에서 필요할 때 선점될 수 있기 때문에 더 낮은 가격이 가능합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-258">The lower price is available because low priority VMs may be preempted when capacity demands it.</span></span> <span data-ttu-id="5e605-259">시간 예산에 유연성이 있다면 우선 순위가 낮은 VM은 모델링 실행 가격을 낮출 수 있는 좋은 방법이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-259">If you have some wiggle room in your time budget, the low priority VMs provide a great way to reduce the price of a modeling run.</span></span>

<span data-ttu-id="5e605-260">다양한 지역에서 실행되는 등, 실행 및 배포를 여러 머신에서 조정해야 한다면 CycleCloud를 활용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-260">If you need to coordinate the execution and deployment across many machines, perhaps with some running in different regions, you can take advantage of CycleCloud.</span></span> <span data-ttu-id="5e605-261">CycleCloud에는 추가 비용이 발생하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-261">CycleCloud costs nothing extra.</span></span> <span data-ttu-id="5e605-262">필요한 경우 데이터 이동을 조정합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-262">It orchestrates data movement when necessary.</span></span> <span data-ttu-id="5e605-263">여기에는 머신 할당, 모니터링, 종료가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-263">This includes allocation, monitoring, and shut down of the machines.</span></span> <span data-ttu-id="5e605-264">우선 순위가 낮은 머신을 처리하여 비용을 억제할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-264">It can even handle low priority machines, making sure expenses are contained.</span></span> <span data-ttu-id="5e605-265">필요한 머신의 조합을 설명하는 것도 가능합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-265">You can go so far as to describe the mix of machines you need.</span></span> <span data-ttu-id="5e605-266">예를 들어, 고급 머신이 필요하나 2개 이상의 코어가 있는 어느 버전에서나 잘 실행될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-266">For example, maybe you need a class of machine but can run well on any version that has 2 or more cores.</span></span> <span data-ttu-id="5e605-267">주기는 이러한 머신 유형에서 코어를 할당할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-267">Cycle can allocate cores across those machine types.</span></span>

## <a name="reporting-on-the-results"></a><span data-ttu-id="5e605-268">결과에 대한 보고</span><span class="sxs-lookup"><span data-stu-id="5e605-268">Reporting on the Results</span></span>

<span data-ttu-id="5e605-269">보험 계리 패키지가 실행되어 결과를 생성한 후에는 여러 규제 당국에 제공할 보고서가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-269">Once the actuarial packages have run and produced their results, you will have several regulator ready reports.</span></span> <span data-ttu-id="5e605-270">규제 당국이나 감사 기관에서 요구하지 않는 인사이트를 생성하는 분석을 수행하기 위해 수많은 새 데이터가 있을 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-270">You will also have a mountain of new data that you may want to analyze to generate insights not required by regulators or auditors.</span></span> <span data-ttu-id="5e605-271">최고 고객의 프로필을 이해하고자 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-271">You may want to understand the profile of your best customers.</span></span> <span data-ttu-id="5e605-272">인사이트를 사용하면 마케팅 및 영업 부서가 더 신속하게 저비용 고객을 파악할 수 있게 저비용 고객의 양태를 알려줄 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-272">Using insights, you can tell marketing what a low-cost customer looks like so that marketing and sales can find them faster.</span></span> <span data-ttu-id="5e605-273">마찬가지로, 보험 보유의 수혜가 가장 큰 그룹을 밝히는 데도 데이터를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-273">Likewise, you can use the data to discover which groups benefit the most from having the insurance.</span></span> <span data-ttu-id="5e605-274">예를 들어, 건강 문제의 조기 진단과 관련하여 연간 건강 검사를 활용하는 사람들을 파악할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-274">For example, you may discover that people who take advantage of an annual physical found out about early stage health issues earlier.</span></span> <span data-ttu-id="5e605-275">이렇게 하면 보험 회사의 시간과 비용이 절감됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-275">This saves the insurance company time and money.</span></span> <span data-ttu-id="5e605-276">이 데이터를 활용하여 고객 베이스의 행동을 촉진할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-276">You can use that data to drive behavior in your customer base.</span></span>

<span data-ttu-id="5e605-277">이를 위해 여러 데이터 과학 도구와 여러 데이터 시각화에 액세스하고자 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-277">To do this, you will want access to plenty of data science tooling as well as some pieces for visualization.</span></span> <span data-ttu-id="5e605-278">수행하려는 조사 규모에 따라 Azure Marketplace에서 프로비전되는 [데이터 과학 VM](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview?WT.mc_id=riskmodel-docs-scseely)에서 출발할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-278">Depending on how much investigation you want to do, you can start with [a Data Science VM](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview?WT.mc_id=riskmodel-docs-scseely) which can be provisioned from the Azure Marketplace.</span></span> <span data-ttu-id="5e605-279">이 VM에는 Windows와 Linux 버전이 모두 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-279">These VMs have both Windows and Linux versions.</span></span> <span data-ttu-id="5e605-280">설치하고 나면 Microsoft R Open, Microsoft ML Server, Anaconda, Jupyter 및 기타 도구를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-280">Installed, you will find Microsoft R Open, Microsoft ML Server, Anaconda, Jupyter, and other tools ready to go.</span></span> <span data-ttu-id="5e605-281">약간의 R 또는 Python 작업을 통해 데이터를 시각화하고 동료들과 인사이트를 공유합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-281">Throw in a little R or Python to visualize the data and share insights with your colleagues.</span></span>

<span data-ttu-id="5e605-282">상세 분석이 필요한 경우 Spark, Hadoop 같은 Apache 데이터 과학 도구와 기타 HDInsight 또는 Databricks를 통한 도구를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-282">If you need to do more analysis, you can use Apache data science tools like Spark, Hadoop, and others via either HDInsight or Databricks.</span></span> <span data-ttu-id="5e605-283">분석을 정기적으로 실행해야 하며 워크플로를 자동화하려는 경우 이런 도구가 더욱 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-283">Use these more for when the analysis needs to be done regularly and you want to automate the workflow.</span></span> <span data-ttu-id="5e605-284">대형 데이터 세트의 라이브 분석에도 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-284">This is also useful for live analysis of large datasets.</span></span>

<span data-ttu-id="5e605-285">관심 있는 항목을 찾은 후에는 결과를 제시할 필요가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-285">Once you have found something interesting, you need to present the results.</span></span> <span data-ttu-id="5e605-286">많은 보험 계리인들은 샘플 결과를 취해 Excel에 가져와 차트, 그래프 및 기타 시각화 요소를 만드는 것에서 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-286">Many actuaries will start by taking the sample results and plugging them into Excel to create charts, graphs, and other visualizations.</span></span> <span data-ttu-id="5e605-287">데이터 상세 분석을 위한 훌륭한 인터페이스를 갖춘 [Power BI](https://docs.microsoft.com/power-bi/?WT.mc_id=riskmodel-docs-scseely)를 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-287">If you want something that also has a nice interface for drilling into the data, take a look at [Power BI](https://docs.microsoft.com/power-bi/?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-288">Power BI는 훌륭한 시각화와 원본 데이터 표시가 가능하며, [정렬되어 주석이 적용된 책갈피](https://docs.microsoft.com/power-bi/desktop-bookmarks?WT.mc_id=riskmodel-docs-scseely)추가를 통해 판독자들에게 데이터를 설명할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-288">Power BI can make some nice visualizations, display the source data, and it allows for explaining the data to the reader through the addition of [ordered, annotated bookmarks](https://docs.microsoft.com/power-bi/desktop-bookmarks?WT.mc_id=riskmodel-docs-scseely).</span></span>

## <a name="data-retention"></a><span data-ttu-id="5e605-289">데이터 보존</span><span class="sxs-lookup"><span data-stu-id="5e605-289">Data Retention</span></span>

<span data-ttu-id="5e605-290">시스템에 가져온 대부분의 데이터는 향후 감사를 위해 보존되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-290">Much of the data you bring into the system needs to be preserved for future audits.</span></span> <span data-ttu-id="5e605-291">데이터 보존 요구 사항은 보통 7~10년이나 요구 사항에 따라 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-291">Data retention requirements typically range from 7 to 10 years, but requirements vary.</span></span> <span data-ttu-id="5e605-292">최소 보존에는 다음이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-292">Minimal retention involves:</span></span>

- <span data-ttu-id="5e605-293">모델에 대한 원래 입력의 스냅샷.</span><span class="sxs-lookup"><span data-stu-id="5e605-293">Snapshot of the original inputs to the model.</span></span> <span data-ttu-id="5e605-294">자산, 부채, 가정, ESG 및 기타 입력이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-294">This includes assets, liabilities, assumptions, ESGs, and other inputs.</span></span>
- <span data-ttu-id="5e605-295">최종 출력의 스냅샷.</span><span class="sxs-lookup"><span data-stu-id="5e605-295">Snapshot of the final outputs.</span></span> <span data-ttu-id="5e605-296">규제 당국에 제시하는 보고서 만들기에 사용되는 데이터가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-296">This includes any data used to create reports presented to regulatory bodies.</span></span>
- <span data-ttu-id="5e605-297">다른 중요한 중간 결과입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-297">Other important, intermediate results.</span></span> <span data-ttu-id="5e605-298">감사자는 모델에서 어떤 결과가 나온 이유에 대해 질문할 것입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-298">An auditor will ask why your model came up with some result.</span></span> <span data-ttu-id="5e605-299">모델이 특정 선택을 내린 이유나 특정 수치에 대한 증거를 보존해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-299">You need to retain evidence about why the model made certain choices or came up with particular numbers.</span></span> <span data-ttu-id="5e605-300">많은 보험 회사는 원래 입력에서 최종 출력을 생성하는 데 사용한 바이너리를 보관합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-300">Many insurers will choose to keep the binaries used to produce the final outputs from the original inputs.</span></span> <span data-ttu-id="5e605-301">그런 다음, 질문을 받으면 중간 결과의 새 사본을 얻기 위해 모델을 다시 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-301">Then, when questioned, they rerun the model to get a fresh copy of the intermediate results.</span></span> <span data-ttu-id="5e605-302">출력이 일치하면 중간 파일에 필요한 설명이 포함될 것입니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-302">If the outputs match, then the intermediate files should also contain the explanations they need.</span></span>

<span data-ttu-id="5e605-303">모델 실행 중에 보험 계리인은 실행에서 요청 로드를 처리할 수 있는 데이터 전달 메커니즘을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-303">During the model run, the actuaries use data delivery mechanisms that can handle the request load from the run.</span></span> <span data-ttu-id="5e605-304">실행이 완료되어 데이터가 더 이상 필요하지 않으면 일부 데이터를 유지합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-304">Once the run is complete and data is no longer needed, they preserve some of the data.</span></span> <span data-ttu-id="5e605-305">최소한 보험 회사는 재생산 가능 요구 사항에 대해 런타임 구성과 입력을 유지해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-305">At a minimum, an insurer should preserve the inputs and the runtime configuration for any reproducibility requirements.</span></span> <span data-ttu-id="5e605-306">데이터베이스는 Azure Blob Storage에서 백업으로 유지되며 서버는 종료됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-306">Databases are preserved to backups in Azure Blob Storage and servers are shut down.</span></span> <span data-ttu-id="5e605-307">고속 스토리지의 데이터도 더 저렴한 Azure Blob Storage로 이동됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-307">Data on high speed storage also moves to the less expensive Azure Blob Storage.</span></span> <span data-ttu-id="5e605-308">Blob Storage에서는 핫, 쿨 또는 보관 등 각 Blob에 사용되는 데이터 계층을 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-308">Once in Blob Storage, you can choose the data tier used for each blob: hot, cool, or archive.</span></span> <span data-ttu-id="5e605-309">핫 스토리지는 자주 액세스하는 파일에 적합합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-309">Hot storage works well for frequently accessed files.</span></span> <span data-ttu-id="5e605-310">쿨 스토리지는 자주 발생하지 않는 데이터 액세스에 최적화되었습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-310">Cool storage is optimized for infrequent data access.</span></span> <span data-ttu-id="5e605-311">보관 스토리지는 감사 가능한 파일을 보관하는 데 적합하지만 대기 시간 비용에서 절약이 가능합니다. 보관 계층 데이터 대기 시간은 시간 단위로 측정됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-311">Archive storage is best for holding auditable files but the price savings comes at a latency cost: archived tier data latency is measured in hours.</span></span> <span data-ttu-id="5e605-312">[Azure Blob Storage: 핫, 쿨 및 보관 스토리지 계층](https://docs.microsoft.com/azure/storage/blobs/storage-blob-storage-tiers?WT.mc_id=riskmodel-docs-scseely)을 참조하여 서로 다른 스토리지 계층을 제대로 이해합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-312">Read [Azure Blob storage: Hot, cool, and archive storage tiers](https://docs.microsoft.com/azure/storage/blobs/storage-blob-storage-tiers?WT.mc_id=riskmodel-docs-scseely) to fully understand the different storage tiers.</span></span> <span data-ttu-id="5e605-313">수명 주기 관리를 통해 만들기에서 삭제까지의 데이터를 관리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-313">You can manage data from creation through deletion with lifecycle management.</span></span> <span data-ttu-id="5e605-314">Blob에 대한 URI는 고정 상태를 유지하나 Blob 저장 위치는 점점 더 저렴해집니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-314">URIs for blobs stay static, but where the blob is stored gets cheaper over time.</span></span> <span data-ttu-id="5e605-315">이런 특징 때문에 많은 Azure Storage 사용자들의 비용과 고민을 크게 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-315">This feature will save a lot of money and headaches for many users of Azure Storage.</span></span> <span data-ttu-id="5e605-316">[Azure Blob Storage 수명 주기 관리](https://docs.microsoft.com/azure/storage/common/storage-lifecycle-managment-concepts?WT.mc_id=riskmodel-docs-scseely)에서 장단점을 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-316">You can learn about the ins and outs in [Managing the Azure Blob Storage Lifecycle](https://docs.microsoft.com/azure/storage/common/storage-lifecycle-managment-concepts?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="5e605-317">자동으로 파일을 삭제할 수 있다는 점이 매력적입니다. 즉 파일 자체가 자동으로 제거될 수 있기 때문에 범주 외의 파일을 참조하여 우발적으로 감사를 확대하지 않게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-317">The fact that you can automatically delete files is wonderful: it means that you won't accidentally expand an audit by referring to a file that is out of scope because the file itself can be removed automatically.</span></span>

## <a name="next-steps"></a><span data-ttu-id="5e605-318">다음 단계</span><span class="sxs-lookup"><span data-stu-id="5e605-318">Next steps</span></span>

<span data-ttu-id="5e605-319">실행하는 회계 계리 시스템에 온-프레미스 그리드 구현이 있다면 해당 그리드 구현이 Azure에서도 실행될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-319">If the actuarial system you run has a on premises grid implementation, that grid implementation will likely run on Azure too.</span></span> <span data-ttu-id="5e605-320">일부 공급 업체의 경우 하이퍼스케일로 실행되는 Azure 구현을 전문으로 하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-320">For some vendors, they have specialized Azure implementations that run at hyperscale.</span></span> <span data-ttu-id="5e605-321">Azure로의 전환 과정에서 내부 도구도 함께 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-321">As part of the move to Azure, move your internal tooling over as well.</span></span> <span data-ttu-id="5e605-322">어느 지역에서나 보험 계리인은 랩톱이나 대규모 환경 등, 데이터 과학 기술이 어디에서나 잘 작동하는 것을 알 수 있었습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-322">Actuaries everywhere have been finding that their data science skills work well on their laptop or with a large environment.</span></span> <span data-ttu-id="5e605-323">기존에 팀이 하고 있는 것을 살펴봅니다. 딥 러닝을 사용하나 한 GPU에서 실행되는 데 몇 시간에서 며칠까지 걸릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-323">Look for things your team already does: maybe you have something that uses deep learning but takes hours or days to run on one GPU.</span></span> <span data-ttu-id="5e605-324">하이엔드 GPU 4개가 있는 머신에서 같은 워크로드를 실행하고 런타임을 살펴보면 기존 항목의 속도 향상이 두드러진 것을 알 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-324">Try running the same workload on a machine with 4 high end GPUs and look at the run times; odds are good you will see significant speedups for things you already have.</span></span>

<span data-ttu-id="5e605-325">향상이 되면 모델링 데이터 공급을 위한 일부 데이터 동기화도 구축해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-325">As things improve, make sure that you also build out some data synchronization to feed the modeling data.</span></span> <span data-ttu-id="5e605-326">모델 실행은 데이터가 준비되어야 시작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-326">A model run cannot start until the data is ready.</span></span> <span data-ttu-id="5e605-327">여기에는 변경된 데이터만 보내는 작업 추가가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-327">This may involve adding some effort so that you send only data which has changed.</span></span> <span data-ttu-id="5e605-328">실제 방법은 데이터 크기에 따라서도 달라집니다. 일부 MB만 업데이트하는 것은 큰 결과를 내지 않지만 기가바이트 업로드 수를 줄이면 속도가 크게 향상됩니다.</span><span class="sxs-lookup"><span data-stu-id="5e605-328">The actual approach depends on the data size too: updating a few MB maybe isn't a big deal but reducing the number of gigabyte uploads will speed things a lot.</span></span>

### <a name="tutorials"></a><span data-ttu-id="5e605-329">자습서</span><span class="sxs-lookup"><span data-stu-id="5e605-329">Tutorials</span></span>

- <span data-ttu-id="5e605-330">R 개발자: [Azure Batch를 사용하여 병렬 R 시뮬레이션 실행](https://docs.microsoft.com/azure/batch/tutorial-r-doazureparallel?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="5e605-330">R Developers: [Run a parallel R simulation with Azure Batch](https://docs.microsoft.com/azure/batch/tutorial-r-doazureparallel?WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="5e605-331">Azure 함수를 사용하여 스토리지와 상호 작용하는 방법을 보여주는 자습서: [Azure Functions를 사용하여 Blob Storage에 이미지 업로드](https://docs.microsoft.com/azure/functions/tutorial-static-website-serverless-api-with-database?tutorial-step=2&WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="5e605-331">Tutorial to show how to use an Azure Function to interact with storage: [Upload images to Blob storage with Azure Functions](https://docs.microsoft.com/azure/functions/tutorial-static-website-serverless-api-with-database?tutorial-step=2&WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="5e605-332">Databricks를 사용하는 ETL: [Azure Databricks를 사용하여 데이터 추출, 변환 및 로드](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="5e605-332">ETL with Databricks: [Extract, transform, and load data using Azure Databricks](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse?WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="5e605-333">HDInsight를 사용하는 ETL: [Azure HDInsight에서 Apache Hive를 사용하여 데이터 추출, 변환 및 로드](https://docs.microsoft.com/azure/hdinsight/hdinsight-analyze-flight-delay-data-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fhadoop%2FTOC.json&amp;bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json&WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="5e605-333">ETL with HDInsight: [Extract, transform, and load data using Apache Hive on Azure HDInsight](https://docs.microsoft.com/azure/hdinsight/hdinsight-analyze-flight-delay-data-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fhadoop%2FTOC.json&amp;bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json&WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="5e605-334">데이터 과학 VM 방법(Linux): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="5e605-334">Data Science VM How To (Linux): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough?WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="5e605-335">데이터 과학 VM 방법(Windows): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="5e605-335">Data Science VM How To (Windows): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things?WT.mc_id=riskmodel-docs-scseely)</span></span>
